# Gamifier: An Ensemble Program for the Game Design Process
_We present the Gamifier ensemble process, combining 3 deep learning models - ThinkerRNN, PolyGen, and PaletteGAN - to generate 3D meshes and color palettes of relevant objects given one word as the user input._

         
<img width="940" alt="Screen Shot 2021-12-10 at 7 15 41 AM" src="https://user-images.githubusercontent.com/75775661/145577205-d2edb198-f7f0-4032-899e-b8d09433945a.png">
         _Poster_


# Introduction
The game design process has historically been a tedious one: from modelling thousands of scene contributions (either in 2D or 3D), to creatively producing unique ways to enhance the objects added to a scene. We are living in a world demanding an increasing amount of realism in the games we play. Additionally, with a correlated increase in computation power, many games of today require a higher level of complexity and intricacy within the objects used to build up the imaginative world of the game. Hence, we present Gamifier: an ensemble program consisting of three deep learning models designed to simplify the game design process. The first of the models is a RNN language model named “Thinker” — trained on both Wikipedia articles and two Harry Potter books — that takes in a user inputs (say, a single idea for an object to be added to the game) and outputs a list of ideas that are related to the first idea. Once this list has been created, it is fed into DeepMind’s PolyGen model — an “Autoregressive Generative Model of 3D Meshes” — which generates 3D objects as meshes from text descriptions (DeepMind, Polygen). Additionally, the list of ideas is inputted into a Conditional Generative Adversarial Network (cGAN) — rebuilt and re-architectured following inspiration from the network “Coloring with Words: Guiding Image Colorization Through Text-based Palette Generation” of Bahng et al. (Bahng et al., Coloring with Words) — in order to output a set of color recommendations for the objects outputted by the initial ThinkerRNN model.  Through combining these three models, we nicknamed the new umbrella model “Gamifier”, as we believe it will simplify the game design process and unlock a range of potential applications in 3D scene creation, augmented reality, and virtual reality.


# Ethics
Recent innovations in virtual and augmented reality — such as the development of the Metaverse (https://about.facebook.com/meta/) — are suggestive of the pathway that many of the world’s leading technology companies, social networks, and other technological entities are leading into. Hence, gaining an understanding of the way a neural network models and predicts three-dimensional objects provides insight into how the worlds we may all be living and participating in could be designed and modeled in the future.

Additionally, the ethical implications of such a model can be extended to biases within the model; one needs to ensure that for a given stimulus the model has an equal probability of producing a random 3-dimensional object that is based off the input, but unrelated to external factors. For instance, if the stimulus is an “instrument”, the model should have an equal probability of producing a western instrument vs. an instrument from Zimbabwe.

Furthermore, 3D models and scenes are hard to generate manually at large scale, and game designers typically rely on existing procedures and datasets, which can be learned by neural networks, given proper representations that are compatible with neural architectures and training approaches. We believe adopting the Deep Learning approach will make game development more accessible, as it switches a large portion of the technical procedures of generating 3D shapes and scenes to pre-trained models.
