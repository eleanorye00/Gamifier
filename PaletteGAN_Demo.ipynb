{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PltqAQN-khiD"
      },
      "source": [
        "# **PaletteGAN-Demo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh_r2kh2k84n"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j0e7zS9dStC",
        "outputId": "89278762-3131-48ce-84af-ae302c083e45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp\n",
            "Cloning into '/tmp/gamifier'...\n",
            "remote: Enumerating objects: 203, done.\u001b[K\n",
            "remote: Counting objects: 100% (203/203), done.\u001b[K\n",
            "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
            "remote: Total 203 (delta 96), reused 116 (delta 41), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (203/203), 15.41 MiB | 19.68 MiB/s, done.\n",
            "Resolving deltas: 100% (96/96), done.\n",
            "/tmp/gamifier\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "import warnings\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import lab2rgb, rgb2lab\n",
        "%cd /tmp\n",
        "%rm -rf /tmp/gamifier\n",
        "!git clone https://github.com/eleanorye00/Gamifier.git \\\n",
        "  /tmp/gamifier\n",
        "%cd /tmp/gamifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgI0bZHYemHf",
        "outputId": "c6cc0718-4194-4e62-b0e9-f4f81e226669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from paletteGAN_data_loader import *\n",
        "from paletteGAN_modules import *\n",
        "from paletteGAN_utils import *\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "path = \"/gdrive/My Drive/CS1470/CS1470 Final Project/glove.6B.100d.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KiTwP23PeFgd"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    args = {\n",
        "        \"palette_dim\": 15,\n",
        "        \"c_dim\": 100,\n",
        "        \"g_hidden_dim\": 128,\n",
        "        \"d_hidden_dim\": 128,\n",
        "        \"lr\": 5e-4,\n",
        "        \"lambda_GAN\": 1,\n",
        "        \"lambda_sL1\": 200,\n",
        "        \"lambda_KL\": 1,\n",
        "        \"beta_1\": 0.5,\n",
        "        \"batch_size\": 32,\n",
        "        \"num_epochs\": 300,\n",
        "        \"embed_file_path\": os.path.join('./data', 'glove.6B.100d.txt')\n",
        "    }\n",
        "    embed_file_path = path ## CHANGE THIS FOR COLAB!\n",
        "    train_dataset, input_dict = t2p_loader(batch_size=args[\"batch_size\"])\n",
        "    print(\"Dataset loading done!\")\n",
        "    args[\"W_emb\"] = load_pretrained_embedding(dictionary=input_dict.word2index,\n",
        "                                              embed_file=embed_file_path,\n",
        "                                              embed_dim=args[\"c_dim\"])\n",
        "    args[\"n_words\"] = len(input_dict.word2index)\n",
        "    print(\"n_words:\", len(input_dict.word2index))\n",
        "\n",
        "    model = PaletteGAN(args=args)\n",
        "    train(model=model, train_loader=train_dataset, num_epochs=args[\"num_epochs\"])\n",
        "    print(\"Training done!\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVHi5C9weVdc",
        "outputId": "ef7692d2-80c6-4e4c-ea58-802838cef267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 10183 palette names...\n",
            "Making text dictionary...\n",
            "Dataset loading done!\n",
            "4463/4646 vocabs are initialized with GloVe embeddings.\n",
            "n_words: 4644\n",
            "Start training...\n",
            "Epoch 0 generator loss: 179.10327 , discriminator loss: 0.0056103985\n",
            "Epoch 10 generator loss: 167.19995 , discriminator loss: 2.524376e-06\n",
            "Epoch 20 generator loss: 166.76819 , discriminator loss: 3.1780644e-07\n",
            "Epoch 30 generator loss: 166.38004 , discriminator loss: 1.5059526e-07\n",
            "Epoch 40 generator loss: 165.89842 , discriminator loss: 4.7636906e-08\n",
            "Epoch 50 generator loss: 165.83235 , discriminator loss: 2.287933e-08\n",
            "Epoch 60 generator loss: 165.55373 , discriminator loss: 1.1692863e-08\n",
            "Epoch 70 generator loss: 165.04169 , discriminator loss: 2.1731853e-06\n",
            "Epoch 80 generator loss: 164.49326 , discriminator loss: 4.6778942e-07\n",
            "Epoch 90 generator loss: 164.33235 , discriminator loss: 1.3989987e-07\n",
            "Epoch 100 generator loss: 163.89862 , discriminator loss: 6.51713e-08\n",
            "Epoch 110 generator loss: 163.67569 , discriminator loss: 3.930566e-08\n",
            "Epoch 120 generator loss: 163.43275 , discriminator loss: 2.1152319e-08\n",
            "Epoch 130 generator loss: 162.77399 , discriminator loss: 1.7440391e-06\n",
            "Epoch 140 generator loss: 162.33224 , discriminator loss: 3.2120212e-07\n",
            "Epoch 150 generator loss: 162.04466 , discriminator loss: 4.0249554e-07\n",
            "Epoch 160 generator loss: 161.44072 , discriminator loss: 2.0131905e-08\n",
            "Epoch 170 generator loss: 160.5021 , discriminator loss: 3.533336e-05\n",
            "Epoch 180 generator loss: 159.99788 , discriminator loss: 6.3671e-08\n",
            "Epoch 190 generator loss: 158.90753 , discriminator loss: 3.739863e-07\n",
            "Epoch 200 generator loss: 140.2923 , discriminator loss: 0.00017064098\n",
            "Epoch 210 generator loss: 139.1347 , discriminator loss: 9.220197e-06\n",
            "Epoch 220 generator loss: 138.33914 , discriminator loss: 1.7786775e-05\n",
            "Epoch 230 generator loss: 136.8875 , discriminator loss: 1.643685e-06\n",
            "Epoch 240 generator loss: 135.6996 , discriminator loss: 4.4712575e-05\n",
            "Epoch 250 generator loss: 134.6136 , discriminator loss: 1.6357691e-06\n",
            "Epoch 260 generator loss: 133.73138 , discriminator loss: 5.277999e-06\n",
            "Epoch 270 generator loss: 132.63853 , discriminator loss: 1.1453059e-06\n",
            "Epoch 280 generator loss: 131.53485 , discriminator loss: 4.7601243e-06\n",
            "Epoch 290 generator loss: 130.88797 , discriminator loss: 2.2038592e-05\n",
            "Epoch 299 generator loss: 129.96715 , discriminator loss: 4.255348e-05\n",
            "Training done!\n"
          ]
        }
      ],
      "source": [
        "model = main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nJ0xw0NHAlgj"
      },
      "execution_count": 41,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "PaletteGAN-Demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}